idea:
  title: LLMs are bad at "conditional forgetting"
  domain: artificial_intelligence
  hypothesis: 'Humans can "conditionally forget" existing knowledge (such as original
    chess rules) and apply new, hypothetical rules in analogical scenarios, whereas
    large language models (LLMs) struggle to do this effectively, even with advanced
    reasoning models.

    '
  background:
    description: 'When giving humans analogical or hypothetical scenarios and rules,
      humans can apply them effectively, such as introducing new rules in chess. However,
      LLMs may struggle in those scenarios, even with the latest reasoning models.
      The hypothesis is that humans can "conditionally forget" what they know and
      apply new rules, while LLMs cannot do this effectively.

      '
  constraints:
    compute: cpu_only
    time_limit: 3600
    budget: 100
  metadata:
    source: IdeaHub
    source_url: https://hypogenic.ai/ideahub/idea/dLfpQ7mR6I8VZ8RLCj06
    idea_id: llms_are_bad_at__conditional_f_20251105_183053_b1949674
    created_at: '2025-11-05T18:30:53.085199'
    status: submitted
    github_repo_name: llm-conditional-forget-b12c
    github_repo_url: https://github.com/ChicagoHAI/llm-conditional-forget-b12c
